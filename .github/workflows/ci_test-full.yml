name: CI full testing

# see: https://help.github.com/en/actions/reference/events-that-trigger-workflows
on:  # Trigger the workflow on push or pull request, but only for the master branch
  push:
    branches: [master]
  pull_request:
    branches: [master]

jobs:
  pytest:

    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        # Something is wrong with windows tests, will need to debug separately.
        os: [ubuntu-20.04, macOS-11]
        python-version: [3.7, 3.9]
        requires: ['minimal', 'latest']
        exclude:
          # - {python-version: 3.7, requires: 'latest'}
          - {python-version: 3.9, requires: 'minimal'}

    # Timeout: https://stackoverflow.com/a/59076067/4521646
    # the reason for high number is MUCH slower tests on macOS and py3.8
    timeout-minutes: 50

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    # Github Actions: Run step on specific OS: https://stackoverflow.com/a/57948488/4521646
    - name: Setup macOS
      if: runner.os == 'macOS'
      run: |
        brew update  # Todo: find a better way...
        brew install libomp  # https://github.com/pytorch/pytorch/issues/20030

    - name: Set min. dependencies
      if: matrix.requires == 'minimal'
      run: |
        python -c "fpath = 'requirements.txt' ; req = open(fpath).read().replace('>=', '==') ; open(fpath, 'w').write(req)"
        python -c "fpath = 'requirements/models.txt' ; req = open(fpath).read().replace('>=', '==') ; open(fpath, 'w').write(req)"
        python -c "fpath = 'requirements/loggers.txt' ; req = open(fpath).read().replace('>=', '==') ; open(fpath, 'w').write(req)"
        python -c "fpath = 'requirements/test.txt' ; req = open(fpath).read().replace('>=', '==') ; open(fpath, 'w').write(req)"

    # Note: This uses an internal pip API and may not always work
    # https://github.com/actions/cache/blob/master/examples.md#multiple-oss-in-a-workflow
    - name: Get pip cache
      id: pip-cache
      run: |
        python -c "from pip._internal.locations import USER_CACHE_DIR; print('::set-output name=dir::' + USER_CACHE_DIR)"

    - name: Cache pip
      uses: actions/cache@v3
      with:
        path: ${{ steps.pip-cache.outputs.dir }}
        key: ${{ runner.os }}-pip-py${{ matrix.python-version }}-${{ matrix.requires }}-${{ hashFiles('requirements.txt') }}-${{ hashFiles('requirements/modules.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-py${{ matrix.python-version }}-${{ matrix.requires }}-

    - name: Install dependencies
      run: |
        python --version
        pip --version
        # python -m pip install --upgrade --user pip
        pip install --requirement requirements/devel.txt --upgrade --quiet --find-links https://download.pytorch.org/whl/cpu/torch_stable.html
        pip list
      shell: bash

    - name: Cache datasets
      uses: actions/cache@v3
      with:
        path: ./datasets
        key: pl-datasets-${{ hashFiles('tests/conftest.py') }}

    - name: Tests
      run: |
        python -m pytest pl_bolts tests -v --cov=pl_bolts --junitxml=junit/test-results-${{ runner.os }}-${{ matrix.python-version }}-${{ matrix.requires }}.xml

    - name: Upload pytest test results
      uses: actions/upload-artifact@v3
      with:
        name: pytest-results-${{ runner.os }}-${{ matrix.python-version }}-${{ matrix.requires }}
        path: junit/test-results-${{ runner.os }}-${{ matrix.python-version }}-${{ matrix.requires }}.xml
      # Use always() to always run this step to publish test results when there are test failures
      if: always()

    - name: Statistics
      if: success()
      run: |
        coverage report
        coverage xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: always()
      # see: https://github.com/actions/toolkit/issues/399
      continue-on-error: true
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: coverage.xml
        flags: cpu,pytest
        env_vars: OS,PYTHON
        name: codecov-umbrella
        fail_ci_if_error: false
